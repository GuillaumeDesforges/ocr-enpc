\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{dsfont}
\usepackage{bbm}
\usepackage{ulem}
\usepackage{stmaryrd}
\usepackage{upquote}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{calc}
\usepackage{enumitem}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{colortbl}

\usepackage{listings}
\lstset{basicstyle=\ttfamily,
  showstringspaces=false,
  commentstyle=\color{red},
  keywordstyle=\color{blue}
}

%%\usepackage[light]{kpfonts}


\newenvironment{oldstyle}{%
    \renewcommand\rmdefault{jkplvos}%
  \renewcommand\sfdefault{jkpssvos}%
  \renewcommand\ttdefault{jkpttvos}%
  \normalfont
}{}
\newcommand\s{\begin{oldstyle}s\end{oldstyle}}
    \newcommand\up{\textsuperscript}


\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[L]{T. \bsc{Viel}, G. \bsc{Desforges}}
\fancyhead[C]{}
\fancyhead[R]{OCR dans des Manuscrits}
\renewcommand{\headrulewidth}{1pt}
\fancyfoot[C]{\thepage}

%\newcolumntype{C}[1]{>{\centering\arraybackslash }b{#1}}
%\setcounter{MaxMatrixCols}{20}
\renewcommand{\footrulewidth}{1pt}

\title{Reconnaissance de Caractères dans des Manuscrits}
\date{\today}
\author{\bsc{Desforges} Guillaume, \bsc{Viel} Théo}

\begin{document}
\thispagestyle{empty}
\begin{center}

    \begin{figure}[!htb]
        \begin{center}
            \includegraphics[width=4cm]{logo_enpc.png}
        \end{center}
    \end{figure}

    \vspace{0.5cm}

    {\large{\bf Département IMI}}

    \vspace{0.2cm}

    {\large{\bf Février 2018 - Mai 2018}}

    \vspace{1.5cm}

    \large{ \bf Projet de Deep Learning}\\
    \vspace{0.2cm}
    {\Large{\bf Reconnaissance de Caractères dans des Manuscrits}}

    \vspace{1cm}

    \large{Guillaume Desforges et Théo Viel},\\
    \vspace{0.2cm}
    \large{Encadrés par Mathieu Aubry, Imagine, LIGM, École des Ponts}

\end{center}
\newpage

\tableofcontents
\appendix
\newpage 

<<<<<<< HEAD:doc/rapport/rapport.tex
\section{Introduction}
=======

\newpage 

\part{Introduction}
>>>>>>>  Maj rapport:Rapport/Rapport.tex

L'objectif de ce projet est de tester différentes méthodes de reconnaissance de texte pour des manuscrits anciens écrits en vieux français. Ces manuscrits sont souvent très difficiles à lire, même pour des initiés. Il s'agit donc d'automatiser une tâche déjà dure pour l'homme.

Le problème de reconnaissance de caractères (OCR) est une application classique des réseaux de neurones. C'est donc ce genre de technique que nous explorerons.

Nous commencerons par utiliser des moteurs de reconnaissance existants, à savoir \texttt{ocropy} et \texttt{Tesseract}. La deuxième partie du projet consistera soit à essayer d'améliorer le fonctionnement de l'un d'eux, soit à implémenter notre propre réseau de neurones. 


\section{Base théoriques et état de l'art}

Insert \sout{meme} relevant info here.


\section{Reconnaissance avec ocropy}

\subsection{Présentation}

\href{https://github.com/tmbdev/ocropy}{GitHub du projet ocropy}

\begin{quotation}
    OCRopus is a collection of document analysis programs, not a turn-key OCR system. In order to apply it to your documents, you may need to do some image preprocessing, and possibly also train new models.

    In addition to the recognition scripts themselves, there are a number of scripts for ground truth editing and correction, measuring error rates, determining confusion matrices, etc. OCRopus commands will generally print a stack trace along with an error message; this is not generally indicative of a problem (in a future release, we'll suppress the stack trace by default since it seems to confuse too many users).
\end{quotation}

\subsection{Entraînement}

Le principe d'entraînement, adapté aux manuscrits, est le suivant : 
\begin{enumerate}[parsep=0.1cm,itemsep=0.1cm,topsep=0.1cm]
    \item On récupère un ensemble de photos de pages d'un livre ;
    \item On les binarise, c'est-à-dire que l'on met tous les pixels soit à 1 soit à 0 ;
    \item On en extrait les lignes ;
    \item On annote un maximum données ;
    \item On sélectionne une partie des données annotées pour l'entraînement (90\% des données annotées par exemple), et on garde le reste pour la validation ;
    \item On entraîne le réseau de neurones sur les données d'entraînement ;
    \item On valide sur les données de validation en regardant l'erreur.
\end{enumerate}

\subsection{Premiers essais}

\subsubsection{Préparation des données}

Afin de nous familiariser avec cet outil, nous avons commencé par binariser et extraire des lignes d'un manuscrit pris sur le site http://www.e-codices.unifr.ch nous-même. Ce premier test nous a permis de bien comprendre les premiers enjeux. En effet, arrivés à l'étape d'annotation des données, nous avons été confrontés à la difficulté que représente la traduction de ces manuscrits. Le processus est fastidieux puisque les mots mais aussi les caractères ont changé depuis.

Par la suite, nous avons abandonné ces données au profit de données annotées nous ayant été mises à disposition par l'ENC.

Nous avons ensuite travaillé sur un manuscrit de la \textit{Chanson d'Otinel} écrit en anglo-normand au XIIIème siècle.

Il est d'une longueur de 46 pages, d'environ 30 lignes chacune. Nous avons pris environ 1300 lignes pour l'entraînement et 100 pour la validation.

\subsubsection{Commandes basiques}

La commande naïve à exécuter pour entraîner un modèle est : \\
\texttt{ocropus-rtrain -o <ModelName> train/*/*.bin.png} \\
On peut également visualiser les étapes avec la commande: \\
\texttt{ocropus-rtrain -o <ModelName> -d 1 train/*/*.bin.png} \\

\noindent A chaque itération, on a un output de la forme suivante : 

\begin{figure}[!h] 
    \center
<<<<<<< HEAD:doc/rapport/rapport.tex
    \includegraphics[width=8cm]{screen_output.png}
=======
    \includegraphics[width=8cm]{../Screenshots/screen_output.png}
>>>>>>>  Maj rapport:Rapport/Rapport.tex
    \caption{Output d'une itération de l'entraînement}
    \label{API}
\end{figure}

Sur la première ligne se trouve d'abord le numéro de l'itération, puis quelques propriétés de l'image étudiée. L'information se contenant dans le lignes suivantes: \\
- \texttt{TRU} est la solution recherchée \\
- \texttt{ALN} est une version allignée de \texttt{TRU} \\
- \texttt{OUT} est le résultat trouvé par le réseau de neurones \\
Un réseau de neurones idéal aurait les 3 lignes identiques. \\

Afin de lancer la validation d'un modèle et d'avoir le pourcentage d'erreur, on utilise les commandes suivantes : \\
- \texttt{ocropus-rpred -m <ModelName> test/*/*.bin.png} \\
- \texttt{ocropus-errs test/*/*.gt.txt} permet d'évaluer la précision du modèle. \\
- \texttt{ocropus-econf test/*/*.gt.txt} donne les erreurs les plus fréquentes.
On peut ajouter \texttt{-C2} pour une contextualisation des erreurs. \\
\\
Sur ce premier entraînement sans préparations, on obtient une erreur de l'ordre de 27\% au bout de 12 000 itérations ce qui est extrêmement mauvais. En effet, l'ensemble des caractères sortant de l'ordinaire ne sont pas reconnus.

\subsubsection{Entraînement avec les caractères spéciaux}
% TODO modifier
\begin{table}[!h]
    \centering
    \begin{tabular}{|l|l|lc|l|l|}
        \hline
        \multicolumn{6}{|c|}{\cellcolor[gray]{0.8}Statistics of the model}                   \\ \hline
        \multicolumn{3}{|l|}{errors}    & \multicolumn{3}{c|}{329}      \\ \hline
        \multicolumn{3}{|l|}{missing}   & \multicolumn{3}{c|}{35}       \\ \hline
        \multicolumn{3}{|l|}{total}     & \multicolumn{3}{c|}{3547}     \\ \hline
        \multicolumn{3}{|l|}{err}       & \multicolumn{3}{c|}{9.275 \%} \\ \hline
        \multicolumn{3}{|l|}{errnomiss} & \multicolumn{3}{c|}{8.289 \%} \\ \hline
    \end{tabular}
    \caption{Résumé de la commande \texttt{ocropus-errs}}
    \label{t1}
\end{table}

Afin d'intégrer les caractères spéciaux à la résolution, la méthode est de les ajouter à la liste des caractères, stockée dans \texttt{char.py}. C'est ce que nous avons fait, mais cela n'a rien changé. Nous avons compris par la suite que nos modifications effectuées étaient correctes, mais qu'il faut relancer la commande d'installation pour les prendre en compte ... \\
\texttt{sudo python setup.py install} \\

\subsubsection{Premières normalisation}

Nous avons donc opté pour une nouvelle méthode, consistant à repérer manuellement les caractères utilisés avec les fichiers textes contenant l'information de référence.
On utilise ajoute à la commande d'entraînement la commande suivante : \\
\texttt{-c train/*/*.gt.txt test/*/*.gt.txt} \\
Ceci indiquant qu'on va chercher les symboles dans les \textit{ground truth} disponibles.
Les trois commandes décrites précédemment nous permettent de remarquer qu'au bout de 5000 itérations, l'erreur est descendue à 20\% seulement. La matrice de confusion nous a permis de voir que le caractère \textit{\s} n'était pas reconnu. Ceci étant du à une normalisation de l'unicode effectuée par la l'appel \texttt{-c}. \\
Pour résoudre ce problème nous avons implémenté un script \texttt{Python} remplaçant les caractères de nos données par leur normalisation \textit{NFC}, et ainsi assurer la symétrie entre les données pouvant être apprises et la solution. Cette normalisation est utilisée par \texttt{ocropy} pour traiter les données lors de l'appel de la fonction \texttt{normalize-text} du module \texttt{common.py}. Cependant, la normalisation du caractère \textit{\s} étant le \textit{s}, déjà présent dans les données, nous l'avons remplacé par un \textit{Z}.

\subsubsection{Analyse des premiers modèles normalisés}

\texttt{Ocropy} nous permet de sauvegarder nos modèles à un nombre d'itération voulue, pour ce premier test nous les avons sauvegardé tous les 1000 itérations. Ensuite, un script \texttt{bash} utilisant les commandes de validations permet d'évaluer tous les modèles, et d'écrire les output de ces commandes dans un fichier \texttt{.txt}. Nous avons réalisé un script \texttt{Python} afin de réaliser le \textit{post-processing} nécessaire au tracé des courbes d'erreurs.

\begin{figure}[!h] 
    \center
<<<<<<< HEAD:doc/rapport/rapport.tex
    \includegraphics[width=10cm]{error_normalized.png}
=======
    \includegraphics[width=10cm]{../Screenshots/error_normalized.png}
>>>>>>>  Maj rapport:Rapport/Rapport.tex
    \caption{Évolution de l'erreur sur les données normalisées.}
    \label{err_norm}
\end{figure}

La meilleure précision est obtenue pour 83000 itérations, on s'attarde donc un peu plus sur ce modèle particulier pour comprendre les défauts de l'apprentissage. La table \ref{t1} résume les statistiques importantes de ce modèle. \\

\begin{table}[!h]
    \centering
    \begin{tabular}{|l|l|lc|l|l|}
        \hline
        \multicolumn{6}{|c|}{\cellcolor[gray]{0.8}Statistics of the model}                   \\ \hline
        \multicolumn{3}{|l|}{errors}    & \multicolumn{3}{c|}{329}      \\ \hline
        \multicolumn{3}{|l|}{missing}   & \multicolumn{3}{c|}{35}       \\ \hline
        \multicolumn{3}{|l|}{total}     & \multicolumn{3}{c|}{3547}     \\ \hline
        \multicolumn{3}{|l|}{err}       & \multicolumn{3}{c|}{9.275 \%} \\ \hline
        \multicolumn{3}{|l|}{errnomiss} & \multicolumn{3}{c|}{8.289 \%} \\ \hline
    \end{tabular}
    \caption{Résumé de la commande \texttt{ocropus-errs}}
    \label{t1}
\end{table}

Ce qui nous intéresse plus est contenu dans la table \ref{t2} et explique les défauts du réseau de neuronnes. \\
On distingue 3 types d'erreurs:
\begin{enumerate}[parsep=0.1cm,itemsep=0.1cm,topsep=0.1cm]
    \item Les erreurs sur les espaces;
    \item Les erreurs sur les caractères superscripts;
    \item Les erreurs sur les lettres semblables. 
\end{enumerate}

\noindent Le premier peut sans doute être éliminé avec un peu de traitement des données, le second également mais causerait sans doute de la perte de sens. Le troisième est plus caractéristique de l'écriture puisque les lettres \textit{u, n, m, i et l} se ressemblent souvent.

\begin{table}[!h]
    \centering
    \begin{tabular}{|ccc|ccc|}
        \hline
        \multicolumn{6}{|c|}{\cellcolor[gray]{0.8} Most frequent confusions}                         \\ \hline
        \multicolumn{3}{|c|}{\cellcolor[gray]{0.9}Without context} & \multicolumn{3}{c|}{\cellcolor[gray]{0.9}With context} \\ \hline
        \#       & output       & truth       & \#   & ouput       & truth        \\ \hline
        28       &              &     \_      & 2    & a $\delta$ u  & a\_$\delta$ u        \\
        12       & \_           & \'~         & 2    & uı\_t        & uı\'~ t    \\
        10       & \_           &             & 2    & ıez         &  ıe-       \\
        6        & \_           & \up{a}      & 1    & e u la lt   & e n la\_lt   \\
        4        & u            & n           & 1    & uı\_ b      & u\'{ı} b        \\
        4        & ı            & \_          & 1    & Ztı         & Ztr         \\
        4        & t            & \_          & 1    & aı\_nZ      & a\'{ı}nZ        \\
        4        & ı            &  r          & 1    & eg ler      & egı\_er      \\
        3        & ı            & u           & 1    & O\_gı       & O gı         \\
        3        & z            & \_          & 1    & e uZ        & e\_uZ        \\ \hline
    \end{tabular}
    \caption{Résumé de la commande \texttt{ocropus-econf}}
    \label{t2}
\end{table}


\subsubsection{Amélioration de la normalisation}

% TODO


<<<<<<< HEAD:doc/rapport/rapport.tex
\subsubsection{Paramètres utiles}
=======

\section{Modification des paramètres d'entraînement}

\subsection{Commandes utiles}
>>>>>>>  Maj rapport:Rapport/Rapport.tex

Pour modifier l'apprentissage, on peut ajouter une des lignes suivantes à la fin de la commande pour lancer l'entraînement, afin d'en modifier les propriétés. \\
\noindent \texttt{--ntrain <Number>} permet de modifier le nombre d'itérations réalisées dans l'entraînement. Plus ce nombre est grand, meilleur sera le résultat du réseau. \\
\texttt{--savefreq <Number>} permet de dire le nombre d'itérations entre chaque sauvegarde du modèle. Ceci nous permettra dans la suite de tracer les courbes d'erreur. \\
\texttt{--lrate <Number>} permet de modifier la vitesse d'apprentissage. \\ (\textit{learning rate}). Un de nos premiers objectifs sera de trouver une bonne valeur de ce paramètre. \\
\texttt{--hiddensize <Number>} permet de modifier un des paramètres de la taille des matrices de notre réseau de neurones. Nous nous intéresserons également à son optimisation. \\

<<<<<<< HEAD:doc/rapport/rapport.tex
ocropus-rtrain -c train/*/*.gt.txt test/*/*.gt.txt -o test7 train/*/*.bin.png --ntrain 200000 --savefreq 1000

\subsubsection{Commandes bash utiles}

\begin{lstlisting}[language=bash]
    ocropus-rpred -m test3-00005000.pyrnn test/*/*.bin.png
    ocropus-errs test/*/*.gt.txt
\end{lstlisting}

\begin{lstlisting}[language=bash]
    ocropus-rtrain -o <modelname> <training-dir>/*/*.bin
    ocropus-rtrain -o myModel -d 1 train/*/*.bin.png
\end{lstlisting}

\begin{lstlisting}[language=bash]
    for i in test8/*.pyrnn.gz; do
        echo "\$i" >> results.txt
        ocropus-rpred -m \$i test/*/*.bin.png
        ocropus-errs test/*/*.gt.txt >> results.txt
        echo "\$i" >> index.txt
    done
\end{lstlisting}

\begin{lstlisting}[language=bash]
    sudo python setup.py install
\end{lstlisting}

\begin{lstlisting}[language=bash]
    ocropus-rtrain -o test8 train2/*/*.bin.png --load test8-00086000.pyrnn
\end{lstlisting}

\begin{lstlisting}[language=bash]
    ocropus-rtrain -c train/*/*.gt.txt test/*/*.gt.txt -o test7 train/*/*.bin.png --load test7-00073000.pyrnn
\end{lstlisting}

\begin{lstlisting}[language=bash]
    ocropus-rpred -m test7-00083000.pyrnn test\_n/*/*.bin.png
\end{lstlisting}

\end{document}

=======
\subsection{Modification de la vitesse d'apprentissage}

\subsection{Modification de la taille du réseau}

\end{document}
>>>>>>>  Maj rapport:Rapport/Rapport.tex
